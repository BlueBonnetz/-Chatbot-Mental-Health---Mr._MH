{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c4bce9a",
   "metadata": {},
   "source": [
    "# Text Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da7b9ed",
   "metadata": {},
   "source": [
    "โมเดลการจำแนกประเภทข้อความ เพื่อจำแนกและคัดกรองปัญหาสุขภาพจิตของผู้ใช้"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ea6348",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pythainlp import word_tokenize\n",
    "from tqdm import tqdm_notebook\n",
    "import re\n",
    "import emoji\n",
    "from plotnine import *\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import ComplementNB\n",
    "import time\n",
    "import joblib\n",
    "from sklearn.metrics import make_scorer, precision_score\n",
    "from datasets import load_dataset\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from mlxtend.classifier import StackingClassifier\n",
    "import itertools\n",
    "from sklearn.svm import SVC\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c71640",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f6d321",
   "metadata": {},
   "source": [
    "ใช้ Library Hugging face ดึงข้อมูล"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30cc6962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# โหลดข้อมูลจาก Hugging Face\n",
    "hf_token = \"Access_dts_r\"\n",
    "dataset_name = \"BBNz/CNC_1\"\n",
    "\n",
    "train_dataset = load_dataset(dataset_name, split='train', use_auth_token=hf_token)\n",
    "test_dataset = load_dataset(dataset_name, split='test', use_auth_token=hf_token)\n",
    "\n",
    "train_df = pd.DataFrame(train_dataset)\n",
    "test_df = pd.DataFrame(test_dataset)\n",
    "#train_df\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5ba175",
   "metadata": {},
   "outputs": [],
   "source": [
    "#มีคำผิดในชุดข้อมูลอยู่บ้างแต่การรันเพื่อแก้คำผิดใช้เวลานานและใช้ทรัพยากรเยอะเลยละไว้ก่อน\n",
    "#from pythainlp.spell import correct\n",
    "\n",
    "# ฟังก์ชันสำหรับการแก้ไขคำผิดในแต่ละแถวของข้อมูล\n",
    "#def correct_text(text):\n",
    "#    return correct(text)\n",
    "\n",
    "# แก้ไขคำผิดในคอลัมน์ 'text'\n",
    "#train_df['text'] = train_df['text'].apply(correct_text)\n",
    "#train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f3ef79",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missing Value\n",
    "#train_df.dropna()\n",
    "#test_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd8fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imbalance Data set \n",
    "#train_df.target.value_counts()/train_df.shape[0]\n",
    "#test_df.target.value_counts()/test_df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.Target.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beb6780",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.Target.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a4d8a7",
   "metadata": {},
   "source": [
    "ทำ Embedding โดยการทำปรับข้อมูล Text เป็น Vector ด้วยวิธี Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d19bff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocess text\n",
    "def preprocess_text(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "#Tokenize texts\n",
    "train_df['tokens'] = train_df['text'].apply(preprocess_text)\n",
    "test_df['tokens'] = test_df['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ba5ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "#Train Word2Vec model on the training data\n",
    "w2v_model = Word2Vec(sentences=train_df['tokens'], vector_size=300, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c06d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function to get average Word2Vec embedding\n",
    "def get_word2vec_embedding(tokens):\n",
    "    embeddings = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(w2v_model.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1205f711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Word2Vec embedding\n",
    "train_df['embedding'] = train_df['tokens'].apply(get_word2vec_embedding)\n",
    "test_df['embedding'] = test_df['tokens'].apply(get_word2vec_embedding)\n",
    "\n",
    "x_train = np.vstack(train_df['embedding'].values)\n",
    "x_test = np.vstack(test_df['embedding'].values)\n",
    "y_train = train_df['Target']\n",
    "y_test = test_df['Target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3943e90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode labels as numeric values เพราะบางโมเดลจะคาดหวังว่า Labels จะต้องเป็นตัวเลขเท่านั้น\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "y_train = y_train_encoded\n",
    "y_test = y_test_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b009c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#เพราะชุดข้อมูลมีความไบแอสมากและเป็นชุดข้อมูลที่เกี่ยวข้องกับการแพทย์จึงให้ความสำคัญ\n",
    "#กับการทำนายหา TP ที่วัดได้จากค่า Precision จึงมีความพยายามทำชุดข้อมูลให้เท่ากันและเยอะขึ้นเพื่อลด\n",
    "#ความไบแอสของโมเดล แน่นอนว่าการใช้ RandomOverSample เองก็ไม่สามารถทำให้ได้ข้อมูลที่มีคุณภาพมากพอ \n",
    "#เมื่อเทียบกับการใช้ ML สร้างข้อความที่ใกล้เคียงกัน แต่มันใช้ทรัพยากรและเวลามากจึงใช้เพียง OverSample\n",
    "#คุณสามารถใช้วิธี Paraphrasing, Synonym Replacement หรือ การสร้างข้อความด้วย AI เช่น GPT เพื่อเพิ่มปประสิทธิภาพของโมเดลได้ถ้ามีเวลาและทรัพยากรมากพอ\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_train_resampled, y_train_resampled = ros.fit_resample(x_train, y_train)\n",
    "x_train = x_train_resampled\n",
    "y_train = y_train_resampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54f8fe64",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1c78b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fine Best Parameters and Hyperparameters ของแต่ละโมเดลที่เหทากะกับ Word2vecและปัญหา Text Classification เพื่อนำไปใช้ต่อกับโมเดล Stacking ต่อไป\n",
    "#เพราะ Stacking Models มีประสิทธิภาพค่อนข้างดีในการแก้ปัญหาประเภท Text Classification\n",
    "#การตั้งค่าด้านล่างมีเพอร์ฟอร์มที่ไม่ดีนัก เฉลี่ยน Precision ในคลาส guilt ประมาณ 0.4 เท่านั้น \n",
    "#อย่างไรก็ดี ฉันเคยตั้งค่าที่ละเอียดกว่านี้(หลัก 0.01) จะไ้ค่าเฉลี่ยประมาณ 0.7-0.8 ซึ่งเพียงพอต่อการใช้งาน \n",
    "#แต่มันจะใช้เวลานานมากหลักหลาย ชม ฉันลดการตั้งค่าลงเป็นแบบด้านล่างเพื่อรันและทดสอบตัวโปรแกรมใหม่ \n",
    "#ดังนั้นคุณสามารถปรับจูนการตั้งค่าเพิ่มเติมเพื่อเพิ่มเพอร์ฟอร์มด้วยตัวเองได้\n",
    "\n",
    "time_start = time.time()\n",
    "\n",
    "#----- KNN -----\n",
    "knn = KNeighborsClassifier()\n",
    "knn_params = {'n_neighbors': range(1, 100, 2)}\n",
    "\n",
    "knn_grid = GridSearchCV(estimator=knn, param_grid=knn_params)\n",
    "knn_grid.fit(x_train, y_train)\n",
    "\n",
    "print('KNN Best Score:', knn_grid.best_score_)\n",
    "print('KNN Best Params:', knn_grid.best_params_)\n",
    "joblib.dump(knn_grid.best_estimator_, 'knn_best_model.pkl')\n",
    "print()\n",
    "\n",
    "#----- Random Forest -----\n",
    "forest = RandomForestClassifier(random_state=0)\n",
    "forest_params = {\n",
    "    'n_estimators': range(10, 100, 1),\n",
    "    'criterion': ['entropy', 'gini'],\n",
    "}\n",
    "forest_grid = GridSearchCV(estimator=forest, param_grid=forest_params)\n",
    "forest_grid.fit(x_train, y_train)\n",
    "\n",
    "print('Random Forest Best Score:', forest_grid.best_score_)\n",
    "print('Random Forest Best Params:', forest_grid.best_params_)\n",
    "joblib.dump(forest_grid.best_estimator_, 'forest_best_model.pkl')\n",
    "print()\n",
    "\n",
    "\n",
    "#-----LinearSVC-----\n",
    "LSVC = LinearSVC(max_iter=100000)\n",
    "LSVC_params = {\n",
    "    'C': np.arange(1, 100, 1),\n",
    "    \n",
    "}\n",
    "\n",
    "LSVC_grid = GridSearchCV(estimator=LSVC, param_grid=LSVC_params)\n",
    "LSVC_grid.fit(x_train, y_train)\n",
    "\n",
    "print('LinearSVC Best Score:', LSVC_grid.best_score_)\n",
    "print('LinearSVC Best Params:', LSVC_grid.best_params_)\n",
    "joblib.dump(LSVC_grid.best_estimator_, 'lsvc_best_model.pkl')\n",
    "print()\n",
    "\n",
    "#-----LogisticRegression-----\n",
    "LR = LogisticRegression()\n",
    "LR_params = {\n",
    "    'C': np.arange(1, 100, 1),\n",
    "    # 'penalty': ['l1', 'l2','elasticnet']\n",
    "}\n",
    "\n",
    "LR_grid = GridSearchCV(estimator=LR, param_grid=LR_params)\n",
    "LR_grid.fit(x_train, y_train)\n",
    "\n",
    "print('LogisticRegression Best Score:', LR_grid.best_score_)\n",
    "print('LogisticRegression Best Params:', LR_grid.best_params_)\n",
    "joblib.dump(LR_grid.best_estimator_, 'lr_best_model.pkl')\n",
    "print()\n",
    "\n",
    "#----- SVM -----\n",
    "svm = SVC()\n",
    "svm_params = {'C': [0.1, 1, 10, 100], 'kernel': ['linear', 'rbf']}\n",
    "\n",
    "svm_grid = GridSearchCV(estimator=svm, param_grid=svm_params, cv=3, n_jobs=-1, verbose=2)\n",
    "svm_grid.fit(x_train, y_train)\n",
    "\n",
    "print('SVM Best Score:', svm_grid.best_score_)\n",
    "print('SVM Best Params:', svm_grid.best_params_)\n",
    "joblib.dump(svm_grid.best_estimator_, 'svm_best_model.pkl')\n",
    "print()\n",
    "\n",
    "#----- XGBoost -----\n",
    "xgb = XGBClassifier(eval_metric='mlogloss')\n",
    "xgb_params = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "xgb_grid = GridSearchCV(estimator=xgb, param_grid=xgb_params, cv=3, n_jobs=-1, verbose=2)\n",
    "xgb_grid.fit(x_train, y_train)\n",
    "print('XGBoost Best Score:', xgb_grid.best_score_)\n",
    "print('XGBoost Best Params:', xgb_grid.best_params_)\n",
    "joblib.dump(xgb_grid.best_estimator_, 'xgb_best_model.pkl')\n",
    "\n",
    "time_end = time.time()\n",
    "print(f'Total Time: {time_end - time_start} - Second')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25112cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"--------------------------- KNN ---------------------------\")\n",
    "knn_best_model = joblib.load('knn_best_model.pkl')\n",
    "knn_best_model.fit(x_train,y_train)\n",
    "knn_best_model.score(x_train,y_train)\n",
    "test_pred = knn_best_model.predict(x_test)\n",
    "test_pred = label_encoder.inverse_transform(test_pred)\n",
    "print(classification_report(test_df['Target'], test_pred))\n",
    "\n",
    "\n",
    "print(\"--------------------- Random Forest -----------------------\")\n",
    "forest_best_model = joblib.load('forest_best_model.pkl')\n",
    "forest_best_model.fit(x_train,y_train)\n",
    "forest_best_model.score(x_train,y_train)\n",
    "test_pred = forest_best_model.predict(x_test)\n",
    "test_pred = label_encoder.inverse_transform(test_pred)\n",
    "print(classification_report(test_df['Target'], test_pred))\n",
    "\n",
    "\n",
    "print(\"----------------------- LinearSVC -------------------------\")\n",
    "lsvc_best_model = joblib.load('lsvc_best_model.pkl')\n",
    "lsvc_best_model.fit(x_train,y_train)\n",
    "lsvc_best_model.score(x_train,y_train)\n",
    "test_pred = lsvc_best_model.predict(x_test)\n",
    "test_pred = label_encoder.inverse_transform(test_pred)\n",
    "print(classification_report(test_df['Target'], test_pred))\n",
    "\n",
    "\n",
    "print(\"------------------- LogisticRegression ---------------------\")\n",
    "lr_best_model = joblib.load('lr_best_model.pkl')\n",
    "lr_best_model.fit(x_train,y_train)\n",
    "lr_best_model.score(x_train,y_train)\n",
    "test_pred = lr_best_model.predict(x_test)\n",
    "test_pred = label_encoder.inverse_transform(test_pred)\n",
    "print(classification_report(test_df['Target'], test_pred))\n",
    "\n",
    "\n",
    "print(\"-------------------------- SVM ----------------------------\")\n",
    "svm_best_model = joblib.load('svm_best_model.pkl')\n",
    "svm_best_model.fit(x_train,y_train)\n",
    "svm_best_model.score(x_train,y_train)\n",
    "test_pred = svm_best_model.predict(x_test)\n",
    "test_pred = label_encoder.inverse_transform(test_pred)\n",
    "print(classification_report(test_df['Target'], test_pred))\n",
    "\n",
    "\n",
    "print(\"-------------------------- XGBoost -------------------------\")\n",
    "xgb_best_model = joblib.load('xgb_best_model.pkl')\n",
    "xgb_best_model.fit(x_train,y_train)\n",
    "xgb_best_model.score(x_train,y_train)\n",
    "test_pred = xgb_best_model.predict(x_test)\n",
    "test_pred = label_encoder.inverse_transform(test_pred)\n",
    "print(classification_report(test_df['Target'], test_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de971044",
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้าง list ของโมเดลที่ดีที่สุด\n",
    "all_best_models = [knn_best_model, forest_best_model,svm_best_model,xgb_best_model, lsvc_best_model, lr_best_model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3528dc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stacking Classifier\n",
    "best_stack_model = None\n",
    "best_stack_score = 0\n",
    "for L in range(2, len(all_best_models)+1):\n",
    "    for subset in itertools.combinations(all_best_models, L):\n",
    "        stack_model = StackingClassifier(classifiers=list(subset), meta_classifier=LogisticRegression())\n",
    "        stack_model.fit(x_train, y_train)\n",
    "        y_pred = stack_model.predict(x_test)\n",
    "        precision = precision_score(y_test, y_pred, average='weighted')\n",
    "        if precision > best_stack_score:\n",
    "            best_stack_score = precision\n",
    "            best_stack_model = stack_model\n",
    "        print(f'ทดสอบ Stacking Model กับ {L} โมเดล - Precision: {precision}')\n",
    "\n",
    "# ประเมินผลโมเดลที่ดีที่สุด\n",
    "y_pred = best_stack_model.predict(x_test)\n",
    "y_pred_labels = label_encoder.inverse_transform(y_pred)\n",
    "y_val_labels = label_encoder.inverse_transform(y_test)\n",
    "print(\"Confusion Matrix ของโมเดล Stacking ที่ดีที่สุด:\\n\", confusion_matrix(y_val_labels, y_pred_labels))\n",
    "print(\"รายงานการจำแนกของโมเดล Stacking ที่ดีที่สุด:\\n\", classification_report(y_val_labels, y_pred_labels))\n",
    "\n",
    "# บันทึกโมเดลที่ดีที่สุดและตัวเข้ารหัส labels\n",
    "joblib.dump(best_stack_model, 'best_stack_model.pkl')\n",
    "joblib.dump(w2v_model, 'word2vec_model.pkl')\n",
    "joblib.dump(label_encoder, 'label_encoder.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d65187",
   "metadata": {},
   "source": [
    "# API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b646548",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ฉันเลือกใช้การทำและสร้าง API เพื่อรันบน LocalHost ด้วยเหตุผลเรื่องคามสะดวกส่วนตัว\n",
    "#คัว API จะทำนายผลจากอินพุตที่ได้รับแล้วแรนด์ด้อมค่าจากผลทำนายเพื่อส่งออก\n",
    "\n",
    "from flask import Flask, request, jsonify\n",
    "import joblib\n",
    "from gensim.models import Word2Vec\n",
    "import numpy as np\n",
    "from pythainlp import word_tokenize\n",
    "import re\n",
    "import emoji\n",
    "import random\n",
    "import threading\n",
    "from pyngrok import ngrok\n",
    "\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Load the models\n",
    "stacking_model = joblib.load('best_stack_model.pkl')\n",
    "w2v_model = joblib.load('word2vec_model.pkl')\n",
    "label_encoder = joblib.load('label_encoder.pkl')\n",
    "\n",
    "statements_for_case_1 = [\n",
    "    \"ผมรู้สึกว่าคุณกำลังมีความรู้สึกหนักใจหรือกังวลใจบางอย่าง และผมเป็นห่วงคุณมาก การทำแบบทดสอบสุขภาพจิตอาจช่วยให้คุณเข้าใจสถานการณ์ของตัวเองมากขึ้นครับ\",\n",
    "    \"ผมเห็นว่าคุณมีความรู้สึกผิดหรือกังวลใจมากเป็นพิเศษ การทำแบบทดสอบสุขภาพจิตอาจเป็นวิธีที่ดีที่จะช่วยคุณค้นหาวิธีการจัดการกับความรู้สึกเหล่านี้ครับ\",\n",
    "    \"จากที่เราได้คุยกัน ผมรู้สึกว่าคุณกำลังเผชิญกับความรู้สึกที่ยากลำบาก การทำแบบทดสอบสุขภาพจิตอาจช่วยให้คุณได้รับคำแนะนำที่เหมาะสมครับ\",\n",
    "    \"ความรู้สึกที่คุณเล่าให้ฟังดูเหมือนจะเป็นสิ่งที่ทำให้คุณเครียดมาก ผมอยากแนะนำให้คุณลองทำแบบทดสอบสุขภาพจิตเพื่อหาวิธีช่วยเหลือครับ\",\n",
    "    \"ผมรู้สึกว่าคุณมีความกังวลใจมาก การทำแบบทดสอบสุขภาพจิตอาจช่วยให้คุณได้เห็นภาพรวมของสุขภาพจิตของตัวเองและหาวิธีจัดการกับมันครับ\",\n",
    "    \"ผมรู้สึกว่าคุณอาจต้องการการสนับสนุนเพิ่มเติม การทำแบบทดสอบสุขภาพจิตอาจช่วยให้คุณได้รับคำแนะนำที่มีประโยชน์มากขึ้นครับ\",\n",
    "    \"ผมเป็นห่วงความรู้สึกของคุณครับ การทำแบบทดสอบสุขภาพจิตอาจเป็นขั้นตอนแรกที่ดีที่จะช่วยให้คุณได้รับการช่วยเหลือที่ถูกต้องครับ\",\n",
    "    \"ความรู้สึกที่คุณเล่าให้ฟังทำให้ผมกังวลใจครับ ผมคิดว่าการทำแบบทดสอบสุขภาพจิตอาจช่วยให้คุณได้รับการสนับสนุนที่เหมาะสมครับ\",\n",
    "    \"ผมรู้ว่าคุณกำลังผ่านช่วงเวลาที่ยากลำบากครับ การทำแบบทดสอบสุขภาพจิตอาจช่วยให้คุณได้รับคำแนะนำที่เป็นประโยชน์และช่วยให้คุณรู้สึกดีขึ้นครับ\",\n",
    "    \"ผมเห็นว่าคุณกำลังเผชิญกับความกังวลใจมาก ผมอยากแนะนำให้คุณลองทำแบบทดสอบสุขภาพจิตครับ มันอาจเป็นเครื่องมือที่มีประโยชน์ในการช่วยคุณจัดการกับความรู้สึกเหล่านี้ครับ\"\n",
    "]\n",
    "\n",
    "statements_for_case_2 = [\n",
    "    \"ผมเข้าใจว่าคุณกำลังเผชิญกับเรื่องที่ยากลำบากอยู่ และผมอยากให้คุณรู้ว่าผมอยู่ที่นี่เพื่อรับฟังและสนับสนุนคุณครับ\",\n",
    "    \"ผมเห็นว่าคุณกำลังมีความกังวลใจ และผมอยากให้คุณรู้ว่าความรู้สึกเหล่านี้เป็นเรื่องปกติ ไม่ต้องกังวลเกินไปครับ\",\n",
    "    \"หากคุณรู้สึกว่าต้องการพูดคุยหรือแชร์ความรู้สึก ผมพร้อมรับฟังเสมอครับ คุณไม่ได้อยู่คนเดียวในเรื่องนี้\",\n",
    "    \"การได้พูดคุยและแชร์ความรู้สึกบางครั้งอาจช่วยให้คุณรู้สึกดีขึ้น ผมอยู่ที่นี่เพื่อฟังคุณครับ\",\n",
    "    \"ผมเข้าใจว่าคุณกำลังผ่านช่วงเวลาที่ไม่ง่าย ผมอยากให้คุณรู้ว่าผมเป็นห่วงและอยู่ที่นี่เพื่อสนับสนุนคุณครับ\",\n",
    "    \"ถ้าคุณรู้สึกว่าต้องการการสนับสนุนเพิ่มเติม อย่าลังเลที่จะบอกผมนะครับ ผมอยู่ที่นี่เพื่อช่วยเหลือคุณ\",\n",
    "    \"คุณกำลังเผชิญกับความยากลำบากและผมเข้าใจ ผมอยู่ที่นี่เพื่อให้กำลังใจและรับฟังความรู้สึกของคุณครับ\",\n",
    "    \"ผมอยากให้คุณรู้ว่าคุณไม่ได้อยู่คนเดียวครับ ทุกคนมีวันที่ไม่ดี และผมอยู่ที่นี่เพื่อช่วยคุณผ่านมันไป\",\n",
    "    \"ผมเห็นว่าคุณกำลังรู้สึกไม่สบายใจ ผมอยากให้คุณรู้ว่าความรู้สึกเหล่านี้เป็นเรื่องธรรมดา และผมพร้อมอยู่เคียงข้างคุณเสมอ\",\n",
    "    \"ถ้าคุณรู้สึกว่าต้องการใครสักคนรับฟัง ผมพร้อมเสมอครับ บางครั้งการได้พูดออกมาก็ช่วยให้เรารู้สึกเบาใจขึ้น\"\n",
    "]\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = emoji.demojize(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "def get_word2vec_embedding(tokens):\n",
    "    embeddings = [w2v_model.wv[word] for word in tokens if word in w2v_model.wv]\n",
    "    if embeddings:\n",
    "        return np.mean(embeddings, axis=0)\n",
    "    else:\n",
    "        return np.zeros(w2v_model.vector_size)\n",
    "\n",
    "class Predict:\n",
    "    @app.route('/predict', methods=['POST'])\n",
    "    def post():\n",
    "        data = request.get_json(force=True)\n",
    "        message = data['message']\n",
    "        \n",
    "        tokens = preprocess_text(message)\n",
    "        features = get_word2vec_embedding(tokens).reshape(1, -1)\n",
    "        \n",
    "        if features is None or len(features) == 0:\n",
    "            return jsonify({\n",
    "                'error': 'Could not process the input text.'\n",
    "            }), 400\n",
    "        \n",
    "        prediction = stacking_model.predict(features)\n",
    "        prediction_label = label_encoder.inverse_transform(prediction)[0]\n",
    "        \n",
    "        if prediction_label == 'guilt':\n",
    "            response_message = random.choice(statements_for_case_1) + \" คุณสามารถทำการทดสอบได้ที่นี่ \" + \"https://checkin.dmh.go.th/main/index.php?type=1\"\n",
    "        elif prediction_label == 'adl':\n",
    "            response_message = random.choice(statements_for_case_2) + \" ไม่ต้องกังวลไป! คุณจะสามารถผ่านมันไปได้! และไม่มีความเสี่ยง จนถึงขั้นต้องทำแบบทดสอบ\"\n",
    "        else:\n",
    "            response_message = \"ไม่พบประเภทที่ตรงกับข้อมูลที่ระบุ\"\n",
    "        \n",
    "        return jsonify({\n",
    "            'prediction': prediction_label,\n",
    "            'message': response_message\n",
    "        })\n",
    "\n",
    "def run_app():\n",
    "    app.run(port=9000, debug=True, use_reloader=False)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # รัน Flask API ใน thread แยก\n",
    "    thread = threading.Thread(target=run_app)\n",
    "    thread.start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08f5866",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "193d67f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
